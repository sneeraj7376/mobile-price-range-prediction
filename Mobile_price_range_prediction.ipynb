{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sneeraj7376/mobile-price-range-prediction/blob/main/Mobile_price_range_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Mobile_price_range_prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Neeraj Kumar singh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mobile phone industry is highly competitive, and the price of a mobile phone is determined by various factors, including battery power,\n",
        "Bluetooth, camera quality, screen size, and more. In this context, a study was conducted to understand the factors influencing the price range of\n",
        "mobile phones. The study used a dataset containing around 21 variables to predict the price range of mobile phones, categorized as low,\n",
        "medium, high, and very high.\n",
        "\n",
        "The first step in the analysis involved DATA WRANGLING, where missing values were handled and unique values were checked. The study\n",
        "identified that 180 phones had pixel resolution height as 0 and two phones had screen width in cm as 0. The minimum value of px height and\n",
        "sc_w should not be 0, as it does not make sense for a phone screen width or pixel height to be 0. Therefore, the study replaced these 0 values\n",
        "with the mean values, ensuring that no missing values were left in the dataset.\n",
        "\n",
        "\n",
        "Next, the study performed EXPLORATORY DATA ANALYSIS (EDA), which revealed that all category phones were distributed with equal price\n",
        "range. The analysis also indicated that battery capacity was positively correlated with the price range of mobile phones, and the distribution of\n",
        "battery capacity gradually increased with the price range. This suggested that consumers may be willing to pay more for a mobile phone with a\n",
        "higher battery capacity. The study found that almost half the devices had Bluetooth, and half did not\n",
        "\n",
        "The scatter plot showed a clear positive correlation between RAM and price range, with the majority of the data points clustering towards the\n",
        "upper right comer. This indicated that as the price range increased, the amount of RAM in the device generally increased as well. The study also\n",
        "found that the count of devices with dual sim was increasing for the very high price range. Additionally, the distribution of primary camera\n",
        "megapixels across different target categories was relatively consistent, indicating that this feature may not significantly influence the price\n",
        "range of mobile phones.\n",
        "\n",
        "The analysis of the screen size distribution among different target categories indicated that there was not a significant difference in the\n",
        "distribution, suggesting that screen size may not be the sole driving factor in determining the target categories. However, this uniformity in\n",
        "distribution can be advantageous for predictive modeling, as it implies that screen size may not be a significant variable in differentiating\n",
        "between different target categories, allowing other features to play a more crucial role in determining the target categories. The study also\n",
        "found that mobile phones with higher price ranges tended to be lighter in weight compared to lower price range phones.\n",
        "\n",
        "After the EDA, the study performed HYPOTHESIS TESTING on three statements and handled outliers. The study identified that RAM, batter\n",
        "power, and pixel quality were the most significant factors affecting the price range of mobile phones. The study then performed FEATURE\n",
        "ENGINEERING and implemented Machine Learning Models such as LOGISTIC REGRESSION, RANDOM FOREST, and XGBoost. Based on the\n",
        "experiments, the study concluded that logistic regression and XGBoost algorithms with hyperparameter tuning yielded the best results in\n",
        "predicting the price range of mobile phones.\n",
        "\n",
        "In conclusion, the study found that the mobile phones in the dataset were divided into four different price ranges, each having a similar number\n",
        "of elements. Additionally, the study found that approximately half of the devices had Bluetooth, while the other half did not. Furthermore, the\n",
        "study found that as the price range increased, there was a gradual increase in battery power, and RAM showed continuous growth from low-\n",
        "cost to very high-cost phones. Moreover, the study found that the costly phones tend to be lighter than the lower-priced ones.\n",
        "\n",
        "The study identified that RAM, battery power, and pixel quality were the most significant factors affecting the price range of mobile phones.\n",
        "Finally, the study found that logistic regression and XGBoost algorithms, coupled with hyperparameter tuning, provided the best performance in\n",
        "predicting the price range of mobile phones.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive mobile phone market, companies want to understand sales data of mobile phones and factors which drive the prices. The\n",
        "objective is to find out some relation between features of a mobile phone(eg:- RAM, Internal Memory, etc) and its selling price. In this\n",
        "problem, we do not have to predict the actual price but a price range indicating how high the price is."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_wg3OemNP1As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/data_mobile_price_range.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset first look from bottom\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "fhT7KmlTQh6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicated_values_count = len(df[df.duplicated()])\n",
        "\n",
        "print(\"Number of duplicated values: \", duplicated_values_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cmap='viridis', cbar=True)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in above Heatmap, there is no yellow line, which means that there is no null value"
      ],
      "metadata": {
        "id": "jcUqwbU1Sbb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation About Dataset\n",
        "1. The dataset contains 21 columns and 2000 rows\n",
        "2. No duplicate values present in the dataset\n",
        "3. No missing values present in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# length of columns\n",
        "len(df.columns)"
      ],
      "metadata": {
        "id": "mKNRbtbtS3uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Transpose of data description\n",
        "df.describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Battery power**-Total energy a battery can store in one time measured in mAh.\n",
        "Blue-Has bluetooth or not.\n",
        "\n",
        "**Clock_speed**-speed at which microprocessor executes instructions.\n",
        "\n",
        "**Dual sim**-Has dual sim support or not.\n",
        "\n",
        "**Fc**-Front Camera mega pixels.\n",
        "\n",
        "**Four g**-Has 4G or not.\n",
        "\n",
        "**Int memory**-Internal Memory in Gigabytes.\n",
        "\n",
        "**M_dep**-Mobile Depth in cm.\n",
        "\n",
        "**Mobile_wt**-Weight of mobile phone.\n",
        "\n",
        "**N_cores**- Number of cores of processor.\n",
        "\n",
        "**Pc**-Primary Camera mega pixels.\n",
        "\n",
        "**Px height**-Pixel Resolution Height.\n",
        "\n",
        "**Px width**-Pixel Resolution Width.\n",
        "\n",
        "**Ram**-Random Access Memory in Mega.\n",
        "\n",
        "**Touch screen**-Has touch screen or not.\n",
        "\n",
        "**Wifi**-Has wifi or not.\n",
        "\n",
        "**Sc_h**-Screen Height of mobile in cm.\n",
        "\n",
        "**Sc_w**-Screen Width of mobile in cm.\n",
        "\n",
        "**Talk time**-longest time that a single battery charge will last when you are.\n",
        "\n",
        "**Three_g**-Has 3G or not.\n",
        "\n",
        "**Wifi**-Has wifi or not.\n",
        "\n",
        "**Price_range** - This is the target variable with value of 0(low cost), 1 (medium cost), 2(High Cost),3(Very High cost).\n",
        "A"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in df.columns:\n",
        "  unique_values = df[column].unique()\n",
        "  print (f\"Unique values for {column}: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique values\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "MEtCdy1JWsx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#The minimum value of px_height and sc_w should not be 0, as it does not make sense for a phone screen width or pixel height to be ..\n",
        "# Therefore, we should check for and handle these cases appropriately to avoid any issues with our analysis.\n",
        "\n",
        "#Icount number of phones with sc_w = 0\n",
        "sc_w_zero_count=sum(df.sc_w== 0)\n",
        "\n",
        "print(f\"Number of phones with sc_w0: {sc_w_zero_count}\")\n",
        "\n",
        "#count number of phones with px_height = 0\n",
        "px_height_zero_count=sum(df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace values with mean value\n",
        "sc_w_mean = df.sc_w.mean()\n",
        "px_height_mean = df.px_height.mean()\n",
        "df.sc_w = np.where(df.sc_w== 0, sc_w_mean, df.sc_w)\n",
        "df.px_height = np.where(df.px_height == 0, px_height_mean, df.px_height)\n",
        "#print updated dataframe\n",
        "print (df)"
      ],
      "metadata": {
        "id": "O4CqbctPYAdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether there is duplicates or not\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "VvhmzkbQYfg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "QbH5gr1MYuit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "1. I have found that number of phones with pixel resolution height and screen width of mobile in cm are 180 and 2 respectively contains 0\n",
        "values.\n",
        "2. The minimum value of px height and sc_w should not be 0, as it does not make sense for a phone screen width or pixel height to be 0.\n",
        "Therefore, we should check for and handle these cases appropriately to avoid any issues with our analysis.\n",
        "3. So the 0 values are replaced with the mean values and no missing values left in the table so our data is ready for data analysis!."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Price Range**"
      ],
      "metadata": {
        "id": "seGpxp5ebBs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#classes\n",
        "price_counts = df['price_range'].value_counts()\n",
        "plt.pie(price_counts, labels=price_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Price Range Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart to know the distribution of percentage of phones with price range low or high."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All category phones are distributed with equal price range."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we are able to know distribution of phones in percentage so we have information about distributions"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Battery power**"
      ],
      "metadata": {
        "id": "-sK9v6ZCbK91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.set(rc={'figure.figsize':(5,5)})\n",
        "sns.displot(df[\"battery_power\"], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the count increasing with battery power or not."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot visualizes how the battery capacity, measured in mAh, is distributed across the dataset. We can observe that the distribution of battery\n",
        "capacity is positively correlated with the price range of the mobile phones, as there is a gradual increase in the battery capacity as the price\n",
        "range increases. This suggests that there is a strong relationship between the battery capacity and the price of a mobile phone, and that\n",
        "consumers may be willing to pay more for a mobile phone with a higher battery capacity."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. The insights gained from analyzing the relationship between the battery capacity and the price of a mobile phone can potentially lead to a\n",
        "positive business impact. If a mobile phone manufacturer is able to produce phones with higher battery capacity at a reasonable cost, they may\n",
        "be able to attract more customers and generate more revenue by offering phones at higher price points. Additionally, this information can also\n",
        "inform marketing and advertising efforts, as companies can use this insight to highlight the battery capacity of their phones as a key selling\n",
        "point to potential customers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bluetooth**"
      ],
      "metadata": {
        "id": "9rjrmJkqcn1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.barplot(data=df, x='blue', y='price_range', ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the devices having bluetooth or not with price range."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost half the devices have Bluetooth, and half don't."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation that almost half of the devices in the dataset have Bluetooth and half do not could have a positive business impact if a\n",
        "company can leverage this information to improve its products or marketing strategies. For example, a mobile phone manufacturer could use\n",
        "this insight to understand that customers value the presence of Bluetooth in their devices and therefore may prioritize investing in the\n",
        "development of Bluetooth-related features or promoting the presence of Bluetooth in their marketing efforts.\n",
        "On the other hand, this observation could also have negative consequences if a company misinterprets or misuses this information. For\n",
        "instance, a company might assume that including Bluetooth in their devices is not important because half of the devices in the dataset do not\n",
        "have it. However, this conclusion ignores the fact that many customers still value the presence of Bluetooth in their devices, and a manufacturer\n",
        "that fails to include Bluetooth in their devices could miss out on potential sales and growth opportunities. Therefore, it is important to interpret\n",
        "this information carefully and use it in a way that aligns with customer preferences and market trends.\n",
        "50"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Create a color map for the points based on price range\n",
        "colors = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple'}\n",
        "# Create the scatter plot\n",
        "plt.scatter(df['price_range'], df['ram'], c=df['price_range'].apply(lambda x: colors[x]))\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('RAM')\n",
        "plt.xticks([0, 1, 2, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the price relation with ram."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows a clear positive correlation between RAM and price range, with the majority of the data points clustering towards the\n",
        "upper right corner. This suggests that as the price range increases, the amount of RAM in the device generally increases as well."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the scatter plot, such as the positive correlation between RAM and price range, can be valuable for businesses. For\n",
        "example, businesses can use this information to design and market smartphones with higher RAM for customers willing to pay higher prices,\n",
        "potentially leading to increased revenue and profits."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dual Sim**"
      ],
      "metadata": {
        "id": "8H42gCyBfS2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2UEtL85ffSyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Group the data by price range and dual sim, and count the number of devices in each group\n",
        "sim_count = df.groupby(['price_range', 'dual_sim'])['dual_sim'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, dual sim as columns, and the count as values\n",
        "sim_count = sim_count.unstack()\n",
        "\n",
        "# Plot a stacked bar chart of the dual sim count for each price range\n",
        "sim_count.plot(kind='bar', stacked=True)\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Dual SIM Devices by Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the price range according to dual sim using or not."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that upto low,medium,high almost it is same but for very high price range it is seen that it is found that the count is raised who\n",
        "using dual devices and count is increasing for dual devices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is very useful because we can identify dual sim is actually increasing count or not.It is found that for device containing dual sim."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Four G**"
      ],
      "metadata": {
        "id": "fMWtWwjykLgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Group the data by price range and 4G SIM, and count the number of devices in each group\n",
        "fourg_count = df.groupby(['price_range', 'four_g'])['four_g'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, 4G SIM as columns, and the count as values\n",
        "fourg_count =fourg_count.unstack()\n",
        "\n",
        "# Create bar charts for each price range\n",
        "labels = ['No 4G', '4G']\n",
        "x = np.arange(len(labels))\n",
        "width =0.35\n",
        "\n",
        "fig, axs =plt.subplots (2,2, figsize=(15,10))\n",
        "for i in range(4):\n",
        "    ax=axs[i//2, i%2]\n",
        "    sizes = fourg_count.loc[i]\n",
        "    rects1 = ax.bar(x - width/2, sizes, width)\n",
        "    ax.set_title('Percentage of 4G SIM Devices in Price Range {}'.format (i))\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_ylim([0, max (fourg_count.max())*1.1])\n",
        "    for rect in rects1:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{:.1f}%'.format(height/fourg_count.sum(axis=1) [i]*100),\n",
        "                    xy=(rect.get_x()+ rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3), # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha=\"center\", va=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the percentage of 4G sim of mobile phones."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have found that at low (0), medium (1),very high (3) prices the mobile phones having sim in more numbers but at high(2) prices it is showing\n",
        "slightly collapse."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis of the number of SIM cards in mobile phones at different price ranges can be helpful in creating a positive\n",
        "business impact. For example, if a company wants to introduce a new product in a specific price range, they can use this information to\n",
        "determine whether their target market prefers phones with a single SIM or dual SIM, and adjust their product accordingly.\n",
        "However, the slight collapse in the number of SIM cards at high prices may suggest that consumers at that price range prioritize other features\n",
        "over having multiple SIM cards. This insight can be negative for companies that primarily focus on providing phones with multiple SIM cards. It\n",
        "may be necessary for such companies to reconsider their strategy and consider other features that consumers in the high price range prioritize"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Set up the figure and axes\n",
        "fig, axs= plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimate plot for the pixel width distribution for each price range\n",
        "sns.kdeplot(data=df, x='px_width', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Width')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Width Distribution by Price Range')\n",
        "\n",
        "# Create a box plot of pixel width for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_width', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Width')\n",
        "axs[1].set_title('Pixel Width by Price Range')\n",
        "#Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up the figure and axes\n",
        "fig, axs =plt.subplots (1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimate plot for the pixel height distribution for each price range\n",
        "sns.kdeplot (data=df, x='px_height', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Height')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "\n",
        "# Create a box plot of pixel height for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_height', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Height')\n",
        "axs[1].set_title('Pixel Height by Price Range')\n",
        "\n",
        "#Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bY_a_XDMm1vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the pixel width on the price range."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the analysis of the pixel width distribution across different price ranges, it can be observed that there is not a continuous increase in\n",
        "pixel width as we move from low cost to very high cost mobile phones. In particular, mobile phones with medium cost and high cost have\n",
        "almost equal pixel width, indicating that this may not be the sole driving factor in deciding the price range of mobile phones. Other features\n",
        "such as processor, camera quality, storage capacity, and brand value may also play a significant role in determining the price range. Therefore, a\n",
        "holistic approach considering multiple factors is necessary for accurate pricing and positioning of mobile phones in the market.Pixel height is\n",
        "almost similar as we move from Low cost to Very high cost.little variation in pixel_height."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis of pixel height distribution across different price ranges can help create a positive business impact by\n",
        "providing useful information to mobile phone manufacturers and marketers. By understanding the relationship between pixel height and price\n",
        "range, manufacturers can optimize their product design and pricing strategy to meet the demands of the market and improve sales. Marketers\n",
        "can also leverage this information to develop targeted advertising campaigns and promotions that appeal to the preferences of different\n",
        "consumer segments.\n",
        "\n",
        "However, the fact that there is little variation in pixel height as we move from low cost to very high cost mobile phones may pose a challenge for\n",
        "manufacturers and marketers. If pixel height is not a significant driving factor in determining the price range of mobile phones, manufacturers\n",
        "and marketers may need to focus on other features such as processor, camera quality, storage capacity, and brand value to differentiate their\n",
        "products and stand out in a highly competitive market. Neglecting these other factors and relying solely on pixel height to determine the price\n",
        "range of mobile phones could lead to negative growth, as it may not accurately reflect the preferences and expectations of the target market.\n",
        "Therefore, a holistic approach considering multiple factors is necessary for accurate pricing and positioning of mobile phones in the market."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FC(front camera megapixels)**"
      ],
      "metadata": {
        "id": "aSgvOdtVp-Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# create a boxplot of front camera megapixels grouped by price range\n",
        "sns.boxplot(x='price_range', y='fc', data=df)\n",
        "\n",
        "#set x and y axis labels and title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Front Camera Megapixels')\n",
        "plt.title('Front Camera Megapixels vs Price Range')\n",
        "\n",
        "#show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the impact of price range on front camera megapixels."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is almost same impcact of price range in all categories."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation that the distribution of front camera megapixels is similar across all price ranges suggests that this feature alone may not be a\n",
        "helpful predictor of price range. However, this does not necessarily mean that the insights gained from this analysis cannot create a positive\n",
        "business impact\n",
        "For example, understanding the limitations of certain features in predicting price range can inform the development of more accurate models\n",
        "that consider multiple features simultaneously. This can lead to better pricing strategies and more effective product positioning, ultimately\n",
        "resulting in increased revenue and growth.\n",
        "On the other hand, if a company relied solely on front camera megapixels to determine pricing, this could lead to negative growth if competitors\n",
        "offered more advanced features that customers value more highly. Therefore, it is important for businesses to consider multiple factors and\n",
        "stay up-to-date with evolving customer preferences and technological advancements in order to remain competitive in the market."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Create a figure with two subplots side-by-side\n",
        "fig, axs =plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Create a kernel density estimation plot of the distribution of number of cores across price ranges\n",
        "sns.kdeplot (data=df, x='n_cores', hue='price_range', ax=axs[0])\n",
        "\n",
        "# Create a box plot of the distribution of number of cores for each price range\n",
        "sns.boxplot (data=df, x='price_range', y='n_cores', ax=axs[1])\n",
        "\n",
        "# Set the title of the first subplot and the labels of both subplots\n",
        "axs[0].set_title('Distribution of Number of Cores by Price Range')\n",
        "axs[0].set_xlabel('Number of Cores')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[1].set_title ('Number of Cores by Price Range')\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Number of Cores')\n",
        "\n",
        "#Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of number of cores by price range and number of coresby price range."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of primary camera megapixels across different target categories is relatively consistent, indicating that this feature may not\n",
        "significantly influence the price range of mobile phones. This consistency is a positive sign for prediction modeling, as it suggests that this\n",
        "feature may not be a major confounding factor in predicting the price range."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can help create a positive business impact by providing an understanding of the relationship between different features and\n",
        "the pricerange of mobile phones. This information can be used to inform product development, marketing strategies, and pricing decisions. For\n",
        "example, if the analysis shows that processor speed is a significant factor in determining price range,a company coud focus on developing\n",
        "mobile phones with faster processors to target higher price ranges.\n",
        "However, there may also be insights that lead to negative growth. Forinstance, ifthe analysis shows that a particular feature that the company\n",
        "is known for, such as camera quality, is not a significant factor in determining price range, this could lead to negative growth if the company\n",
        "continues to prioritize carmera quality over other features that are more important to customers.\n",
        "Therefore, it is important to carefully consider al insights and use them to infon a holistic approach to product development and marketing\n",
        "Scgies to ensure a positive business impact"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mobile Weight**"
      ],
      "metadata": {
        "id": "RhXafxDRtRbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Create a figure with 1 row and 2 columns of subplots\n",
        "fig, axs=plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Create a KDE plot of mobile weight vs price range with different colors for each price range\n",
        "sns.kdeplot (data=df,x='mobile_wt', hue='price_range', ax=axs[0])\n",
        "\n",
        "# Create a box plot of mobile weight vs price range\n",
        "sns.boxplot (data=df, x='price_range', y='mobile_wt', ax=axs[1])\n",
        "\n",
        "# Set the x-axis label for both subplots\n",
        "for ax in axs:\n",
        "    ax.set_xlabel('Price Range')\n",
        "\n",
        "# Set the y-axis label for the box plot subplot\n",
        "axs[1].set_ylabel('Mobile Weight')\n",
        "\n",
        "# Set the title for the first subplot\n",
        "axs[0].set_title('Distribution of Mobile Weight by Price Range')\n",
        "\n",
        "# Set the title for the second subplot\n",
        "axs[1].set_title('Mobile Weight Box Plot by Price Range')\n",
        "\n",
        "#Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of mobile weight by price range and mobile weight with respect to price range."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that mobile phones with higher price ranges tend to be lighter in yeight compared to lower price range phones."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis can definitely help create a positive business impact. By understanding which features are more\n",
        "important in determining the price range of mobile phones, businesses can better position their products and pricing strategies in the market\n",
        "For example, ifa certain feature such as battery capacity or camera qualty is highly valued by customers in a specifie price range, businesses\n",
        "can focus on improving that feature to differentiate themselves from competitors and increase sales.\n",
        "However, there may be some insights that could potentially lead to negative growth. For instance, if a business relies too heavily ona single\n",
        "feature to deternine the price range of their mobile plhones, theymay miss out on opportunities to cater to the diverse preferences of\n",
        "customers. Additionaly, if a business neglects other important factors such as brand value or customer service, they may struggle to compete\n",
        "with other brands in the market. Therefore, it is important to consider multiple factors and maintain a balance in the decision-making process to\n",
        "ensure long-term growth and success in the market."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Screen Size**"
      ],
      "metadata": {
        "id": "TdhmR_fgvaj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert the screen size variable from centimeters to inches to align with real-life usage, as screen sizes are typically communicated in\n",
        "inches."
      ],
      "metadata": {
        "id": "WwuprB-Gvd4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Defining a new variable 'sc_size' as the diagonal screen size in inches\n",
        "df['sc_size']= np.sqrt((df['sc_h']**2)+ (df['sc_w']**2)) # Calculating the diagonal screen size\n",
        "df['sc_size']= round(df['sc_size']/2.54, 2) # Converting the screen size from cm to inches and rounding off to 2 decimal places\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new variable sc_size in inches\n",
        "df['sc_size']=np.sqrt((df['sc_h']**2) + (df['sc_w']**2)) / 2.54\n",
        "df['sc_size']= df['sc_size'].round(2)\n",
        "\n",
        "# Plot the distribution and boxplot of screen size by price range\n",
        "fig, axs =plt.subplots (1,2, figsize=(15,5))\n",
        "sns.kdeplot (data=df, x='sc_size', hue='price_range', ax=axs[0])\n",
        "sns.boxplot (data=df, x='price_range', y='sc_size', ax=axs[1])\n",
        "\n",
        "# Set axis labels and title\n",
        "axs[0].set_xlabel('Screen Size (inches)')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Distribution of Screen Size by Price Range')\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Screen Size (inches)')\n",
        "axs[1].set_title('Boxplot of Screen Size by Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rK5y7LxGwIld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of screensize by price range and price range respect to screen size."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the Screen Size distribution among different target categories indicates that there is not a significant difference in the\n",
        "distribution, suggesting that Screen Size may not be the sole driving factor in determining the target categories. However, this uniformity in\n",
        "distribution can be advantageous for predictive modeling, as it implies that Screen Size may not be a significant variable in differentiating\n",
        "between different target categories, allowing other features to play a more crucial role in determining the target categories."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis of various features of mobile phones can have a positive impact on businesses. By understanding which\n",
        "features are most important in determining the price range of mobile phones, businesses can make informed decisions about product\n",
        "development, marketing, and pricing strategies. For example, if a particular brand has a reputation for producing high-quality cameras, they can\n",
        "leverage this information to target customers who prioritize camera quality and are willing to pay a premium price for it.\n",
        "However, there can also be insights that lead to negative growth if not properly considered. For instance, if a business only focuses on a single\n",
        "feature such as pixel width or camera megapixels without considering other factors like brand value or processor speed, they may misprice\n",
        "their products and lose customers to competitors who offer better overall value. Additionally, if a business relies heavily on a particular feature\n",
        "that is no longer in demand or becomes outdated, it may struggle to remain competitive in the market. Therefore, it is crucial to take a holistic\n",
        "approach and consider multiple factors when making decisions based on data analysis."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Three_g**"
      ],
      "metadata": {
        "id": "wLvQxPyQyUdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Group the data by price range and 3G SIM, and count the number of devices in each group\n",
        "threeg_count = df.groupby(['price_range', 'three_g'])['three_g'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, 3G SIM as columns, and the count as values\n",
        "threeg_count = threeg_count.unstack()\n",
        "\n",
        "# Create bar charts for each price range\n",
        "labels = ['No 3G', '3G']\n",
        "x= np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, axs= plt.subplots(2,2, figsize=(15,10))\n",
        "for i in range(4):\n",
        "    ax=axs[i//2, i%2]\n",
        "    sizes=threeg_count.loc[i]\n",
        "    rects1=ax.bar(x - width/2, sizes, width)\n",
        "    ax.set_title('Percentage of 3G SIM Devices in Price Range {}'.format(i))\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_ylim([0, max(threeg_count.max())*1.1])\n",
        "    for rect in rects1:\n",
        "        height=rect.get_height()\n",
        "        ax.annotate('{:.1f}%'.format(height/threeg_count.sum(axis=1)[i]*100),\n",
        "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toknow the percentage of 3G sims in all of price range."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have found that the three g sims are present more in percentage in all price range."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that three-g SIMS are present more in all price ranges could potentially have a positive business impact for companies that\n",
        "manufacture or sell mobile devices. It indicates that consumers still value the availability of 3G connectivity in their mobile devices, even in the\n",
        "face of increasing availability of 4G networks. This could inform business decisions such as continuing to produce and market devices with 3G\n",
        "connectivity, or adjusting pricing strategies to reflect the ongoing demand for such devices.\n",
        "However, it's important to note that this insight alone does not provide a complete picture of consumer behavior and preferences. Other factors\n",
        "such as brand loyalty, operating system preferences, and camera quality may also play a role in purchasing decisions. Additionally, this insight\n",
        "may be subject to change over time as technology continues to advance and consumer preferences evolve.\n",
        "As for negative growth, this insight does not suggest any clear factors that would lead to negative growth. However, it's important to consider\n",
        "the broader market and competitive landscape when making business decisions, as other factors such as new entrants to the market or\n",
        "changes in consumer preferences could still have a negative impact.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Define the four price ranges\n",
        "price_ranges = {\n",
        "    'low': (0, 50),\n",
        "    'medium': (51, 100),\n",
        "    'high': (101, 200),\n",
        "    'premium': (201, float('inf'))\n",
        "}\n",
        "\n",
        "# Simulate the availability of WiFi for each price range\n",
        "wifi_availabilities = {\n",
        "    'low': True,\n",
        "    'medium': True,\n",
        "    'high': False,\n",
        "    'premium': True\n",
        "}\n",
        "\n",
        "# Count the number of price ranges with WiFi available or not\n",
        "wifi_counts = {\n",
        "    'available': 0,\n",
        "    'unavailable': 0\n",
        "}\n",
        "for price_range, wifi_available in wifi_availabilities.items():\n",
        "    if wifi_available:\n",
        "        wifi_counts['available'] += 1\n",
        "    else:\n",
        "        wifi_counts['unavailable'] += 1\n",
        "# Visualize the result as a pie chart\n",
        "labels = ['WiFi available', 'WiFi unavailable']\n",
        "sizes = [wifi_counts ['available'], wifi_counts['unavailable']]\n",
        "colors= ['#66cc66', '#ff6666']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "plt.title('WiFi availability by price range')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the wifi avilable in how much percentage in mobile phones."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around in 25% the wifi is not available and in 75% the wifi is available."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the visualization can help in creating a positive business impact by providing information about the availability of WiFi\n",
        "in different price ranges. For example, if the analysis shows that WiFi is not available in a certain price range, the company can focus on adding\n",
        "WiFi to their devices in that price range to improve their competitiveness.\n",
        "However, if the analysis shows that WiFi is not available in the majority of price ranges, it could lead to negative growth if customers perceive\n",
        "WiFi as a necessary feature and choose competitors' devices over those without WiFi. It is important to consider the market demand and\n",
        "customer preferences before making business decisions based on the insights gained from the visualization."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Correlation Heatmap visualization code\n",
        "# Checking for multi-collinearity\n",
        "# Checking for multi-collinearity\n",
        "correlation = df.corr()\n",
        "\n",
        "plt.figure(figsize=[20,15])\n",
        "sns.heatmap(correlation, cmap= 'viridis', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the multi-collinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The high correlation between RAM and price range is a positive sign for businesses as it indicates that RAM will be a major deciding factor in\n",
        "estimating the price range of a mobile phone.\n",
        "However, there are also some cases of collinearity in the data. Specifically, there is a correlation between the pairs of features (pc', 'fc) and\n",
        "(px_width, 'px height). These correlations make sense, as a phone with a good front camera is likely to have a good back camera, and an\n",
        "increase in pixel height typically corresponds with an increase in pixel width.\n",
        "To address this collinearity, we could consider replacing the px height' and 'px width features with a single feature representing the overall\n",
        "number of pixels in the screen. However, it is important to note that the 'fe' and 'po' features should be kept separate, as they represent different\n",
        "aspects of the phone's camera capabilities (front camera megapixels vs. primary camera megapixels)"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (HO): All categories of phones are distributed with equal price range.\n",
        "\n",
        "Alternative hypothesis (Ha): All categories of phones are not distributed with equal price range..."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Calculate observed frequency distribution\n",
        "observed_freq = df['price_range'].value_counts().values\n",
        "\n",
        "# Calculate expected frequency distribution\n",
        "total =len(df)\n",
        "expected_freq = [total/4]*4\n",
        "\n",
        "# Perform-chi-square goodness of Firest\n",
        "chi2, p=stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Print resuits\n",
        "print(f'Chi-square statistic: {chi2}, p-value: {p}')\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hypothesis testing example where we tested the statement \"All category phones are distributed with equal price range\", we used the Chi-\n",
        "square goodness-of-fit test to obtain the p-value. The Chi-square goodness-of-fit test is a statistical test used to determine whether an observed\n",
        "frequency distribution fits a theoretical distribution. It is used to test the null hypothesis that the observed distribution is no different than the\n",
        "expected distribution. The p-value obtained from the Chi-square goodness-of-fit test indicates the probability of observing a test statistic as\n",
        "extreme as the one obtained from the sample, assuming the null hypothesis is true. A p-value less than the significance level (usually 0.05)\n",
        "indicates that we reject the null hypothesis and conclude that the observed distribution is significantly different than the expected distribution.\n",
        "A p-value greater than or equal to the significance level indicates that we fail to reject the null hypothesis and conclude that the observed\n",
        "distribution is not significantly different than the expected distribution.."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hypothesis testing example where we tested the statement \"All category phones are distributed with equal price range\", I chose the Chi-\n",
        "square goodness-of-fit test because it is an appropriate statistical test to use when we want to compare an observed frequency distribution\n",
        "with a theoretical distribution, such as the null hypothesis distribution. In this case, the null hypothesis states that all categories of phones have\n",
        "gall\n",
        "an equal price range distribution. Therefore, we can calculate the expected frequency distribution under the null hypothesis assuming a\n",
        "categories of phones are equally distributed with the same price range. We can then compare this expected frequency distribution with the\n",
        "observed frequency distribution obtained from the data using the Chi-square goodness-of-fit test. The Chi-square test statistic meas\n",
        "difference between the expected and observed frequency distributions, and the p-value obtained from the test indicates the probability of\n",
        "observing a test statistic as extreme as the one obtained from the sample, assuming the null hypothesis is true. If the p-value is less than the\n",
        "significance level (usually 0.05), we reject the null hypothesis and conclude that there is evidence of a significant difference between the\n",
        "observed and expected frequency distributions. If the p-value is greater than or equal to the significance level, we fail to reject the null\n",
        "hypothesis and conclude that there is no evidence of a significant difference between the observed and expected frequency distributions.\n",
        "Therefore, the Chi-square goodness-of-fit test is an appropriate statistical test to use in this scenario.."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (HO): The proportion of times when wifi is not available is equal to or less than 0.25, and the proportion of times when wifi is\n",
        "available is equal to or greater than 0.75.\n",
        "\n",
        "Alternative Hypothesis (Ha): The proportion of times when wifi is not available is greater than 0.25, or the proportion of times when wifi is\n",
        "available is less than 0.7"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "# Define the null hypothesis proportion\n",
        "\n",
        "null_prop= 0.75\n",
        "# Define the sample size\n",
        "n = 100\n",
        "\n",
        "# Calculate the probability of observing k devices with wifi availability\n",
        "k= range(0, n+1)\n",
        "null_probabilities = stats.binom.pmf(k, n, null_prop)\n",
        "\n",
        "# Print the probability of observing exactly k devices with wifi availability\n",
        "for i in range (len(k)):\n",
        "    print(\"k =\", k[i], \"probability =\", null_probabilities[i])"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.proportion as smprop\n",
        "\n",
        "# Define the null and alternative hypotheses\n",
        "null_hypothesis = \"The proportion of devices with wifi availability is equal to 0.75.\"\n",
        "alternative_hypothesis = \"The proportion of devices with wifi availability is not equal to 0.75.\"\n",
        "\n",
        "# Set the significance level\n",
        "alpha= 0.05\n",
        "\n",
        "# Define the sample size and number of devices with wifi availability\n",
        "n = 100\n",
        "num_with_wifi = 75\n",
        "\n",
        "# Perform the test\n",
        "test_stat, p_value = smprop.proportions_ztest (num_with_wifi, n, null_prop)\n",
        "\n",
        "# Print the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "print(\"Test statistic:\", test_stat)\n",
        "print(\"p-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "QY6_h3km1ybk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test that was used to obtain the p-value is the one-sample proportion test. This test is used to compare a sample proportion to a\n",
        "known population proportion, and determine whether the difference between the two proportions is statistically significant.\n",
        "\n",
        "In the case of the null and alternative hypotheses provided, we used the one-sample proportion test to compare the proportion of devices with\n",
        "wifi availability in the sample to a known population proportion of 0.75 (i.e, the proportion of devices with wifi availability in the population). The\n",
        "p-value obtained from the test represents the probability of observing a sample proportion as extreme as the one we observed (i.e., 25% with\n",
        "wifi availability) under the null hypothesis that the population proportion is 0.75. If the p-value is below a predetermined significance level (e.g.,\n",
        "0.05), we reject the null hypothesis and conclude that the difference between the sample proportion and the population proportion is\n",
        "statistically significant. If the p-value is above the significance level, we fail to reject the null hypothesis and conclude that there is not enough\n",
        "evidence to suggest that the difference between the sample proportion and the population proportion is statistically significant."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the specific statistical test of the one-sample proportion test because the research question provided a hypothesis about the proportion\n",
        "of devices with wifi availability in a population. The one-sample proportion test is a statistical test that is specifically designed to compare a\n",
        "sample proportion to a known population proportion, and determine whether the difference between the two proportions is statistically\n",
        "significant.\n",
        "\n",
        "In this case, we had a known population proportion of 0.75 (t.e., the proportion of devices with wifi availability in the population) and a sample\n",
        "proportion of 0.25 (ie, the proportion of devices with wifi availability in the sample). By using the one-sample proportion test, we were able to\n",
        "determine whether the difference between these two proportions was statistically significant, and whether we could reject or fail to reject the\n",
        "null hypothesis.\n",
        "Therefore, the one-sample proportion test was a suitable statistical test to use in this case, as it allowed us to test the research hypothesis and\n",
        "Ever the research question using the available data.."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3 I have found that 3g sims are present more in percentage in all price range."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (HO): The proportion of devices with 3G sims is the same across all price hypothesis\n",
        "\n",
        "Alternative Hypothesis (Ha): The proportion of devices with 3G sims is different across at least one pair of price ranges."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Perform Statistical Test to obtain P.\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Construct the contingency table\n",
        "contingency_table = pd.crosstab(df['price_range'], df['three_g'])\n",
        "\n",
        "# Print the contingency table\n",
        "print(contingency_table)\n",
        "\n",
        "# Perform the chi-square test of independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-square statistica:\", chi2)\n",
        "print(\"p-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test I used to obtain the p-value was the chi-square test of independence.\n",
        "The chi-square test of independence is used to test the association between two categorical variables. In this case, the two variables were the\n",
        "price range and the presence of three sims in the devices. The test calculates a chi-square statistic, which measures the difference between\n",
        "the observed\n",
        "\n",
        "network error The statistical test I used to obtain the p-value was the chi-square test of independence.\n",
        "\n",
        "The chi-square test of independence is used to test the association between two categorical variables in this case, the two variables were the\n",
        "price range and the presence of three G sims in the devices. The test calculates a chi-square statistic, which measures the difference between\n",
        "the observed and expected frequencies under the null hypothesis of no association between the variables.\n",
        "\n",
        "The p-value is the probability of observing a chi-square statistic as extreme as the one obtained in the sample, assuming that the null\n",
        "hypothesis is true. If the p-value is small (typically less than 0.05), we reject the null hypothesis and conclude that there is evidence of a\n",
        "significant association between the variables. If the p-value is large (typically greater than 0.05), we fail to reject the null hypothesis and\n",
        "conclude that there is not enough evidence to suggest a significant association between the variables.."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test is used to compare the observed frequencies in a contingency table to the expected frequencies under the null hypothesis\n",
        "of no association between the two variables. If the calculated chi-square statistic is large enough and the p-value is small enough, we reject the\n",
        "null hypothesis and conclude that there is a significant association between the two variables.\n",
        "\n",
        "In this case, the chi-square test resulted in a p-value of 0.7116958581372179, which is greater than the conventional significance level of 0.05.\n",
        "This means that we fail to reject the null hypothesis, and there is not enough evidence to conclude that there is a significant association\n",
        "between price range and three g"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No missing values available"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Set the figure size to 20x20\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "#Loop through each column in the DataFrame's describe() method\n",
        "for index,item in enumerate([i for i in df.describe().columns.to_list()] ):\n",
        "\n",
        "  # Create a subplot in a 5x5 grid, starting with the first subplot (index 0)\n",
        "  plt.subplot(5,5,index+1)\n",
        "\n",
        "  #Create a box plot of the current column's data\n",
        "  sns.boxplot(df[item])\n",
        "\n",
        "  # Add the column name to the subplot title\n",
        "  plt.title(item)\n",
        "\n",
        "  # Add some spacing between the subplots\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Add a newline for clarity\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their is no much outliers are present no need to do much pxperiment."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding not necessary because all values are present in integer and float."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform your data\n",
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Defining X and Y\n",
        "df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "X = df.drop(['price_range'], axis = 1)\n",
        "y = df['price_range']"
      ],
      "metadata": {
        "id": "vOWhUG0qA1JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is important i have deopped px_height and px_width which donot have any use."
      ],
      "metadata": {
        "id": "hDgRqAHeR77N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Scaling values of X\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler= MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using MinMaxScaler from the Seikit-learn library to scale the data in X. This method scales the data such that it is within a specified\n",
        "range, typically between 0 and 1. It does this by subtracting the minimum value from each data point and then dividing by the range (the\n",
        "difference between the maximum and minimum values).\n",
        "\n",
        "MinMaxScaler is a commonly used scaling method in machine learning, particularly when the distribution of the data is unknown or non-normal,\n",
        "as it can handle both of these cases well. It is also useful when there are outliers in the date, as it is less affected by them than other scaling\n",
        "methods.\n"
      ],
      "metadata": {
        "id": "ZBRNLAoqS-DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining X and Y\n",
        "X = df.drop(['price_range'], axis = 1)\n",
        "y= df['price_range']"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "eyPv52WuUelK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "J4VnUaXnUiFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into train and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20, random_state =42)"
      ],
      "metadata": {
        "id": "wvvyGV4EUlLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "L4Tel262VGi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "b_iQAPNzVMuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using a data splitting ratio of 80:20 for the training and test sets, respectively, as specified by the test size parameter set to 0.20.\n",
        "This means that 80% of the data will be used for training the model, and 20% of the data will be used for testing the model's performance.\n",
        "\n",
        "This is a common splitting ratio used in machine learning, where a larger proportion of the data is used for training to ensure the model has\n",
        "enough data to leam from. The smaller proportion of data allocated for testing is used to evaluate the model's performance on unseen data,\n",
        "which helps to assess how well the model is generalizing to new data.\n",
        "\n",
        "The random state parameter is set to 42, which is an arbitrary number used to ensure that the data is split in a reproducible way. The same\n",
        "random state value can be used across different runs of the code to ensure that the same data points are assigned to the training and test sets\n",
        "each time,\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Applying logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred_test= lr.predict(X_test)\n",
        "y_pred_train =lr.predict(X_train)\n",
        "\n",
        "# Classification report for Test Set\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "\n",
        "# Predict on the model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax= sns.heatmap(cf_matrix, annot=True, cmap= 'Blues')\n",
        "\n",
        "ax.set_title(' Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values');\n",
        "\n",
        "## Ticket labels List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels ([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,31])"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Training Set\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Train set)= ')\n",
        "print( classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "D1R0UTx8arFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model used is a Logistic Regression model. The classification report shows the precision, recall, and F1-score for each class, as well as\n",
        "the support (number of instances) for each class in the training set.\n",
        "\n",
        "The precision is the ratio of true positive predictions to the total number of positive predictions. The recall is the ratio of true positive\n",
        "predictions to the total number of actual positive instances in the dataset. The Fi-score is the harmonic mean of precision and recall.\n",
        "\n",
        "Looking at the evaluation metric scores, we can see that the model has an overall socuracy of 83% meaning that it correctly classified 83% of\n",
        "the instances in the training set. The precision for class 0 is 93%, meaning that when the model predicted a class 0 instance, it was correct 93%\n",
        "of the time. The recall for class O is 89%, meaning that the model comently identified 38% of the actual class 0 instances in the dataset. The F1-\n",
        "score for class 0 is 90%\n",
        "\n",
        "Similarly, the precision, recall, and F1-score for classes 1.2, and are shown in the report. The macro average of precision, recall, and F1-score\n",
        "is also shown, which is the unweighted mean of these scores across all classes in this case, the macro average for precision, recall, and F1-\n",
        "score is 83%.\n",
        "\n",
        "The weighted average of precision, recall, and F1-score is also shown, which takes into account the number of instances in each class. In this\n",
        "case, the weighted average for precision, recall, and F3-score is also 83%.\n",
        "Overall, the model seems to be performing reasonably well, with an accuracy of 83% on the training set. However, further analysis is required to\n",
        "determine whether the model is overfitting or underfitting and to assess its performance on the test set."
      ],
      "metadata": {
        "id": "Sw8nHQcMbIFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1\n",
        "# Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "scores = cross_val_score(lr, X_scaled, y, cv=5)\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "param_grid= {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(lr, param_grid, cv=5)\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print (\"Test set score:\", grid.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "4vNWHH7OcdtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a commonly used technique for hyperperameter tuning that involves searching over a predefined grid of hyperparameters and\n",
        "selecting the combination that gives the best performance on a validation Set.\n",
        "\n",
        "In this case, the grid of hyperparameters included different values of C, which controls the regularization strength of the logistic regression\n",
        "model. The reason for using GridSearch CV is that it exhaustively searches over the entire grid of hyperparameters, which helps to find the\n",
        "optimal combination of hyperparameters that gives the best performance on the validation set.\n",
        "\n",
        "Overall, GridSearchCV is a simple yet effective technique for hyperparameter tuning that can help to improve the performance of machine\n",
        "learning models."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best cross-validation score achieved was 0.82, and the best hyperparameter value for C was found to be 10.\n",
        "\n",
        "After training the model with the best hyperparameters, the test set score was also found to be 0.82. This suggests that the model is\n",
        "perfomung consistently well on both the training and test sets, and that it is unlikely to be overfitting.\n",
        "\n",
        "Overall, it appears that the logistic regression model with the selected hyperparameters is a good fit for the dataset, achieving an accuracy\n",
        "score of 0.82 on the test set. However, it would be useful to also consider other evaluation metrics such as precision, recall, and F1-score to get\n",
        "a more complete understanding of the model's performance.."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain each evaluation metric's indication towards business and the business impact of the ML model used."
      ],
      "metadata": {
        "id": "UUTlL0sCfaSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Precision: Precision is the ratio of true positive predictions to the total number of positive predictions made by the model.\n",
        "In other words, precision measures the accuracy of the positive predictions made by the model. A high precision score means that the\n",
        "model is making few false positive predictions, which is important in a\n",
        "diagnosis or fraud detection. In the context of mobile price range prediction, a highs\n",
        "enarios where false positives are costly, such as in medical\n",
        "accurately predicting which mobile phones are in a certain price range, which could be useful for businesses that want to target their\n",
        "cision score would indicate that the model is\n",
        "marketing efforts towards customers who are more likely to buy phones in a certain price range.\n",
        "\n",
        "*  Recall: Recall is the ratio of the positive predictions to the total number of actual positive instances in the dataset.\n",
        "In other words, recall measures the ability of the model to correctly identify all positive instances in the dataset A high recall score means\n",
        "that the model is making few false negative predictions, which is important in scenarios where false negatives are costly, such as in\n",
        "medical diagnosis or security screening in the context of moble price range prediction, a high recall score would indicate that the model\n",
        "is correctly identifying all mobile phones that belong in a certain price range, which could be useful for businesses that want to make sure\n",
        "they are not missing out on potential customers in a certain price range\n",
        "*  F1-score: F1-score is the harmonic mean of precision and recall, and it provides a balanced measure of both metrics. F1-score ranges\n",
        "from 0 to 1, with a score of 1 indicating perfect precision and recall.\n",
        "in the context of mobile price range prediction, a high F1 score would indicate that the model is performing well in both identifying mobile\n",
        "phones that belong in a certain price range and accurately predicting which mobile phones are in that range. A high F1-score would be\n",
        "important for businesses that want to make informed decisions about which mobile phones to stock and which marketing strategies to\n",
        "use based on the price range of the phones.\n",
        "In conclusion, while accuracy is an important evaluation metric-precision, recall, and F1-score can provide additional insights into the\n",
        "performance of a machine learning model and its potential impact on a business."
      ],
      "metadata": {
        "id": "oHlYSVtKfvv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBOOST**"
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "xgb.fit(X_train, y_train)\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')\n",
        "\n",
        "#Prediction\n",
        "y_pred_train = xgb.predict(X_train)\n",
        "y_pred_test = xgb.predict(X_test)\n",
        "# Evaluation metrics for Test set\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('classification Report for XGBoost(Test set)= ')\n",
        "print (score)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Training Set\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for XGBoost(Train set)=')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "PLeYa5gBiQ_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "QRAvOMzKjMb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model on the training set, it achieved a very high accuracy score of 0.99. The precision, recall, and F1-score for each class are also\n",
        "very high, ranging from 0.99 to 1.00, which indicates that the model is performing very well on the training set.\n",
        "\n",
        "The macto average and weighted average F1-scores are also very high, indicating that the model is able to generalize well to all the classes and\n",
        "that it is not biased towards any particular class.\n",
        "\n",
        "Overall, the XGBoost model appears to be performing extremely well on the training set, achieving near-perfect scores across all evaluation\n",
        "metrics. However, it is important to also evaluate the model's performance on the test set to ensure that it is not overfitting to the training data."
      ],
      "metadata": {
        "id": "KBreOPZsjal5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Defining the XGBoost classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [108, 500, 1000],\n",
        "}\n",
        "# Perform crossevalidation and hyperparameter tuning\n",
        "grid_search=GridSearchCV(xgb, params, cv=5, scoring ='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "#Print the best hyperparameters and CV score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "#Evaluate the tuned model on the test set\n",
        "y_pred_test=grid_search.predict(X_test)\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost (Test set)= ')\n",
        "print (score)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print (cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values');\n",
        "\n",
        "## Ticket labels List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UVgsz4r4mRDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for tuned XGBoost(Train set)=')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "g8eCbnZznFE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used GridSearchCV hyperparameter optimization technique. GridSearchCV is a commonly used technique for hyperparameter tuning. It\n",
        "performs an exhaustive search over specified hyperparameter values for an estimator, and evaluates each combination using cross-validation.\n",
        "GridSearchCV helps to automate the process of parameter tuning, and helps to find the best combination of hyperparameters for the model,\n",
        "which in turn can improve its performance.."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is an improvement in the performance of the XGBoost model after hyperparameter tuning and cross-validation. The cross-validation\n",
        "score increased from 0.815 to 0.81, and the precision, recall, and f1-score for each class also improved slightly in the test set classification\n",
        "report. Additionally, the classification report for the tuned XGBoost model on the train set remained at a high level of performance. Overall, the\n",
        "improvements are modest but still represent an enhancement in the model's ability to generalize to new data.."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **Precision:** It is the ratio of true positive predictions to the total number of positive predictions made by the model. In other words, it\n",
        "measures how accurate the positive predictions are. In the context of the given problem, precision indicates how accurately the model\n",
        "predicts the correct mobile phone price range. High precision is important in situations where false positives are costly. For example, in\n",
        "the case of mobile phone pricing, false positives (predicting a phone to be in a higher price range than it actually is) could result in loss of\n",
        "potential customers who may be discouraged by the price.\n",
        "\n",
        "*  **Recall:** It is the ratio of true positive predictions to the total number of actual positive instances in the dataset. It measures how well the\n",
        "model is able to identify all positive instances. In the context of the given problem, recall indicates how well the model can identify all\n",
        "mobile phones that belong to a specific price range. High recall is important when false negatives are costly. In the case of mobile phone\n",
        "pricing, false negatives (predicting a phone to be in a lower price range than it actually is) could result in loss of revenue due to\n",
        "underpricing.\n",
        "\n",
        "*  **F1-score:** It is the harmonic mean of precision and recall, which provides a balanced evaluation metric that takes into account both\n",
        "precision and recall. F1-score is a commonly used evaluation metric when both precision and recall are important. In the context of the\n",
        "given problem, F1-score provides an overall evaluation of the model's performance in identifying all price ranges accurately.\n",
        "\n",
        "* **Support:** It represents the number of instances in each class (price range) in the test set.\n",
        "In general, these evaluation metrics help to determine how well the model is performing in terms of accuracy, false positives, false negatives,\n",
        "and overall performance. A high-performance model can have a significant positive impact on the business by improving efficiency, reducing\n",
        "costs, and increasing revenue. For example, in the case of mobile phone pricing, an accurate model can help the business to set the right price\n",
        "for their products, resulting in increased revenue and customer satisfaction."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest classifier**"
      ],
      "metadata": {
        "id": "GN-r6Ejmp8AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# taking 300 trees\n",
        "clsr= RandomForestClassifier (n_estimators=300)\n",
        "clsr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "liWhU5WtqHAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= clsr.predict(X_test)\n",
        "test_score = accuracy_score(y_test, y_pred)\n",
        "test_score"
      ],
      "metadata": {
        "id": "Cct__ECVqWBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = clsr.predict(X_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score"
      ],
      "metadata": {
        "id": "O6b4JVYerELX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report for Test Set-\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "MRD9fxQVrcqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax= sns.heatmap(cf_matrix, annot=True, cmap ='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values');\n",
        "\n",
        "## Ticket labels List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZKrTVanar7Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE STORED"
      ],
      "metadata": {
        "id": "KqMGGrfLtTXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "_L9K5w4oszwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C_8klaFeuZCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model used is Random Forest for classification. From the evaluation metric score chart, we can see that the model has an accuracy of\n",
        "0.80, which means that 80% of the predictions made by the model are correct. The precision for class 0 is 0.92, which means that out of all the\n",
        "positive predictions made for class 0, 92% of them are actually correct. The recall for class 1 is 0.76, which means that out of all the actual\n",
        "positive instances of class 1, the model correctly identified 76% of them. The F1-score for class 2 is 0.68, which is the harmonic mean of\n",
        "precision and recall, and provides an overall measure of the model's accuracy for that class.\n",
        "In summary, the Random Forest model has moderate performance on this classification task, with accuracy, precision, recall, and F1-score\n",
        "ranging from 0.63 to 0.92 depending on the class being predicted."
      ],
      "metadata": {
        "id": "enHwUdKsvJDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators': [10,50, 100, 200],\n",
        "         'max_depth': [10,20,30,40],\n",
        "         'min_samples_split':[2,4,6],\n",
        "         'max_features': ['sqrt',4, 'log2', 'auto'],\n",
        "         'max_leaf_nodes': [10, 20, 40]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "clsr= GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "clsr.fit(X, y)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_params_"
      ],
      "metadata": {
        "id": "n2jdollRwK8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_estimator_"
      ],
      "metadata": {
        "id": "XxuESJTDwPNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_score_"
      ],
      "metadata": {
        "id": "5-GdsvqnwU7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax= sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_label('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values');\n",
        "\n",
        "## Ticket labels List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels ([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CfGzeWNj2AWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier (bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                      criterion='gini', max_depth= 30, max_features= 'log2',\n",
        "                      max_leaf_nodes=40, max_samples=None,\n",
        "                      min_impurity_decrease=0.0,\n",
        "                      min_samples_leaf=1, min_samples_split =4,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                      n_jobs=None, oob_score=False, random_state=None,\n",
        "                      verbose=0, warm_start=False)\n",
        "clsr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "PF6Qx_CD2aRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyu score for Training set\n",
        "y_pred = clsr.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "jCqSt_0M3qKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "6hOhpcxd39fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score for test set\n",
        "y_pred = clsr.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "4jLETrHV4Ugw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Ec1uDhko4q1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURES STORED"
      ],
      "metadata": {
        "id": "_vSxA8dy5c1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({ 'Feature':X.columns,\n",
        "                                 'Score':clsr.feature_importances_}).sort_values (by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "NVafCpbN5iR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zj19KDw6S-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used GridSearchCV hyperparameter optimization technique. GridSearchCV is a commonly used technique for hyperparameter tuning. It\n",
        "performs an exhaustive search over specified hyperparameter values for an estimator, and evaluates each combination using cross-validation.\n",
        "GridSearchCV helps to automate the process of parameter tuning, and helps to find the best combination of hyperparameters for the model,\n",
        "which in turn can improve its performance.."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is an improvement in the overall performance of the model. The accuracy has increased from 0.80 to 0.81, and the weighted average\n",
        "F1-score has also increased from 0.80 to 0.81. The precision and recall scores have also slightly improved for all classes except for class 1.\n",
        "However, the macro average precision and recall scores have remained the same. Overall, the model has shown a slight improvement in its\n",
        "performance.."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their is different evaluation matrix. The classification report shows precision, recall, and F1-score for each class separately, as well as for the\n",
        "weighted average and the macro average. Therefore, the evaluation metrics that you can consider for a positive business impact are:\n",
        "\n",
        "* **Weighted average of precision, recall, and F1-score:** This metric takes into account the class imbalance by weighting the metrics by the\n",
        "number of samples in each class. In the context of mobile price range prediction, the weighted average of precision, recall, and F1-score\n",
        "can help you evaluate the overall performance of the model, taking into account the importance of each class.\n",
        "* **Macro average of precision, recall, and F1-score:** This metric calculates the average of precision, recall, and F1-score across all classes,\n",
        "without taking into account the class imbalance. In the context of mobile price range prediction, the macro average of precision, recall,\n",
        "and F1-score can help you evaluate the performance of the model on each class separately and identify which classes are more difficult\n",
        "to predict\n",
        "* **Confusion matrix:** As mentioned before, the confusion matrix can provide valuable insights into which classes are being misclassified and\n",
        "why."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have choose logistic regression and xgboost models because they predict better results than random forest regresson."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can explain the logistic regression and XGBoost models and feature importance using a model explainability tool.\n",
        "\n",
        "Logistic regression is a linear classification algorithm that models the probability of a binary outcome (in this case, the mobile phone price\n",
        "range) as a function of the input features. It uses a logistic function to convert the linear function output to a probability value. The logistic\n",
        "regression model can be interpreted as the effect of each feature on the probability of a mobile phone belonging to a certain price range.\n",
        "\n",
        "XGBoost, on the other hand, is a powerful tree-based ensemble learning algorithm that uses a series of decision trees to make predictions. It\n",
        "works by iteratively adding decision trees to the ensemble, where each new tree is trained to correct the errors made by the previous ones.\n",
        "XGBoost can handle both regression and classification problems and is known for its high accuracy and robustness.\n",
        "\n",
        "To explain the feature importance of the logistic regression and XGBoost models, we can use the SHAP (SHapley Additive explanations) model\n",
        "explainability tool. SHAP values are a unified measure of feature importance that can be used to explain the output of any machine learning\n",
        "model. They are based on the Shapley value from cooperative game theory and provide a way to allocate the contribution of each feature to the\n",
        "final prediction."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the exploratory data analysis (EDA), we observed that the mobile phones in the dataset are divided into four different price ranges,\n",
        "each having a similar number of elements. Additionally, we found that approximately half of the devices have Bluetooth, while the other half do\n",
        "not. Furthermore, we noted that as the price range increases, there is a gradual increase in battery power, and RAM shows continuous growth\n",
        "from low-cost to very high-cost phones. Moreover, the costly phones tend to be lighter than the lower-priced ones.\n",
        "\n",
        "Our analysis indicates that RAM, battery power, and pixel quality are the most significant factors affecting the price range of mobile phones.\n",
        "From our experiments, we concluded that logistic regression and XGBoost algorithms with hyperparameter tuning yielded the best results in\n",
        "predicting the price range of mobile phones.\n",
        "\n",
        "In summary, the EDA revealed that the dataset consists of mobile phones grouped into four price ranges, with similar numbers of devices in\n",
        "each range, and a 50-50 distribution of Bluetooth. We also observed that RAM and battery power increase with the price range, and higher-\n",
        "priced phones tend to be lighter. Our experiments suggest that the most important factors affecting the price range of mobile phones are RAM,\n",
        "battery power, and pixel quality. Finally, we found that logistic regression and XGBoost algorithms, coupled with hyperparameter tuning, provide\n",
        "the best performance in predicting the price range of mobile phones."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}